{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6df71e6-cdd2-43d9-8589-8470a043e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3prl.nn import S3PRLUpstream\n",
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e3083f-fbd0-4954-b17b-c770819cf8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: https://huggingface.co/s3prl/converted_ckpts/resolve/main/audio_base_ls.pt\n",
      "Destination: /home/eernst/.cache/s3prl/download/a303ec55138fdcb6c5359385c2a14b7045bb5b2c74b14239b32791d77424e8dd.audio_base_ls.pt\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 696M/696M [00:35<00:00, 20.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "upstream = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edbaf880-8583-4266-abda-0b058630a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3PRLUpstreamMLPDownstrem(pl.LightningModule):\n",
    "    def __init__(self, state, upstream='data2vec', layer=-1, hidden_layers=2, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.upstream = S3PRLUpstream(upstream)\n",
    "        self.mapping = state['class_map']\n",
    "        upstream_dim = self.upstream.hidden_sizes[0]\n",
    "        layer_dims = [upstream_dim] + [hidden_dim]*hidden_layers\n",
    "        self.net = torch.nn.Sequential(*[torch.nn.Sequential(torch.nn.Linear(dim_in, dim_out), torch.nn.ReLU()) for dim_in, dim_out in zip(layer_dims[:-1],layer_dims[1:])])\n",
    "        if isinstance(layer, int):\n",
    "            layer = [layer]\n",
    "        if layer == 'all':\n",
    "            layer = list(range(len(self.upstream.hidden_sizes)))\n",
    "        self.avg_weights = torch.nn.Parameter(torch.ones(len(layer),))\n",
    "        self.layer = layer\n",
    "        self.out_layer = torch.nn.Linear(layer_dims[-1],len(self.mapping))\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            hidden, last = upstream(x['wav'], wavs_len=x['wavs_len'])\n",
    "        hidden = torch.stack(hidden).transpose(0,1)\n",
    "        print(hidden.shape)\n",
    "        w = torch.nn.functional.softmax(self.avg_weights, dim=0)\n",
    "        avg_hidden = torch.sum(hidden[:,self.layer]*w[None,:,None,None],dim=1)\n",
    "        y = self.out_layer(self.net(avg_hidden))\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yhat=self(batch)\n",
    "        y=batch['class_id']\n",
    "        return torch.nn.functional.cross_entropy(yhat,y)\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a748e2b-b409-42cb-b395-3d7760755431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "state=joblib.load('../speech_hypertuning/experiments/experiment_lr/test_load_dataset/state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e64758cf-87ad-454d-9ba0-c40c2a850ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S3PRLUpstreamMLPDownstrem(state, layer='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95605645-5e3a-4610-9649-db26867b73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 100, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 1251])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model({'wav':torch.randn((2,32000)),'wavs_len':torch.tensor([32000,16000])}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8376e4af-5c39-4e7a-9a19-a1b65df8a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, last = upstream(torch.randn((2,32000)), wavs_len=torch.tensor([32000,16000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0da4c6f7-554a-4d4f-8105-2d0333e31e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1f57d8-3c11-4366-9c0d-775cf7d87bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.stack(hidden).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a6ee68-fe9b-47b8-a973-14a4b25933e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[:,[2,3,5]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2813a2a-c851-43cf-b0cf-c52b44c41b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS,L,T,D\n",
    "x,L,x,x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
