{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df71e6-cdd2-43d9-8589-8470a043e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3prl.nn import S3PRLUpstream\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from typing import Any, Dict, Union, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbaf880-8583-4266-abda-0b058630a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3PRLUpstreamMLPDownstrem(pl.LightningModule):\n",
    "    def __init__(self, state, upstream='data2vec', layer=-1, hidden_layers=2, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.upstream = S3PRLUpstream(upstream)\n",
    "        self.mapping = state['class_map']\n",
    "        upstream_dim = self.upstream.hidden_sizes[0]\n",
    "        layer_dims = [upstream_dim] + [hidden_dim]*hidden_layers\n",
    "        self.net = torch.nn.Sequential(*[torch.nn.Sequential(torch.nn.Linear(dim_in, dim_out), torch.nn.ReLU()) for dim_in, dim_out in zip(layer_dims[:-1],layer_dims[1:])])\n",
    "        if isinstance(layer, int):\n",
    "            layer = [layer]\n",
    "        if layer == 'all':\n",
    "            layer = list(range(len(self.upstream.hidden_sizes)))\n",
    "        self.avg_weights = torch.nn.Parameter(torch.ones(len(layer),))\n",
    "        self.layer = layer\n",
    "        self.out_layer = torch.nn.Linear(layer_dims[-1],len(self.mapping))\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            hidden, last = upstream(x['wav'], wavs_len=x['wavs_len'])\n",
    "        hidden = torch.stack(hidden).transpose(0,1)\n",
    "        print(hidden.shape)\n",
    "        w = torch.nn.functional.softmax(self.avg_weights, dim=0)\n",
    "        avg_hidden = torch.sum(hidden[:,self.layer]*w[None,:,None,None],dim=1)\n",
    "        y = self.out_layer(self.net(avg_hidden))\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yhat=self(batch)\n",
    "        y=batch['class_id']\n",
    "        return torch.nn.functional.cross_entropy(yhat,y)\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3PRLUpstreamMLPDownstrem(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state: Dict[str, Any],\n",
    "        upstream: str = 'data2vec',\n",
    "        upstream_layers_output_to_use: Union[str, List[int], int] = -1,\n",
    "        hidden_layers: int = 2,\n",
    "        hidden_dim: int = 128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mapping = state['class_map']\n",
    "\n",
    "        self.upstream = S3PRLUpstream(upstream)\n",
    "        upstream_dim = self.upstream.hidden_sizes[0]\n",
    "\n",
    "        layer_dims = [upstream_dim] + [hidden_dim] * hidden_layers\n",
    "\n",
    "        self.downstream = torch.nn.Sequential(*[torch.nn.Sequential(torch.nn.Linear(dim_in, dim_out), torch.nn.ReLU()) for dim_in, dim_out in zip(layer_dims[:-1],layer_dims[1:])])\n",
    "        self.out_layer = torch.nn.Linear(layer_dims[-1],len(self.mapping)) # FIXME: add this at the end of the downstream?\n",
    "\n",
    "        if isinstance(upstream_layers_output_to_use, int):\n",
    "            upstream_layers_output_to_use = [upstream_layers_output_to_use]\n",
    "        if upstream_layers_output_to_use == 'all':\n",
    "            upstream_layers_output_to_use = list(range(len(self.upstream.hidden_sizes)))\n",
    "        self.upstream_layers_output_to_use = upstream_layers_output_to_use\n",
    "\n",
    "        self.avg_weights = torch.nn.Parameter(torch.ones(len(upstream_layers_output_to_use),))\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            hidden, _ = self.upstream(x['wav'], wavs_len=x['wavs_len'])\n",
    "        hidden = torch.stack(hidden).transpose(0,1)\n",
    "\n",
    "        w = torch.nn.functional.softmax(self.avg_weights, dim=0)\n",
    "        \n",
    "        avg_hidden = torch.sum(hidden[:,self.upstream_layers_output_to_use]*w[None,:,None,None],dim=1)\n",
    "        \n",
    "        return self.out_layer(self.downstream(avg_hidden))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yhat = self(batch)\n",
    "        y = batch['class_id']\n",
    "        return torch.nn.functional.cross_entropy(yhat,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a748e2b-b409-42cb-b395-3d7760755431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "state=joblib.load('../speech_hypertuning/experiments/experiment_lr/test_load_dataset/state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64758cf-87ad-454d-9ba0-c40c2a850ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = S3PRLUpstreamMLPDownstrem(state, upstream_layers_output_to_use='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95605645-5e3a-4610-9649-db26867b73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model({'wav':torch.randn((2,32000)),'wavs_len':torch.tensor([32000,16000])}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376e4af-5c39-4e7a-9a19-a1b65df8a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, last = upstream(torch.randn((2,32000)), wavs_len=torch.tensor([32000,16000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4c6f7-554a-4d4f-8105-2d0333e31e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f57d8-3c11-4366-9c0d-775cf7d87bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.stack(hidden).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6ee68-fe9b-47b8-a973-14a4b25933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden[:,[2,3,5]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2813a2a-c851-43cf-b0cf-c52b44c41b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS,L,T,D\n",
    "x,L,x,x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
