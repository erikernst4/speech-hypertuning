{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7289fceb-b587-4584-b06c-4e8eb5c69ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from lightning import LightningModule\n",
    "from s3prl.nn import S3PRLUpstream\n",
    "\n",
    "\n",
    "class S3PRLUpstreamMLPDownstreamForCls(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state: Dict[str, Any],\n",
    "        upstream: str = 'wavlm_base_plus',\n",
    "        upstream_layers_output_to_use: Union[str, List[int], int] = 'all',\n",
    "        hidden_layers: int = 2,\n",
    "        hidden_dim: int = 128,\n",
    "        optimizer: Optional[Any] = None,\n",
    "        lr_scheduler: Optional[Any] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.opt_state = state\n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.mapping = state['speaker_id_mapping']\n",
    "        self.num_classes = len(self.mapping)\n",
    "\n",
    "        self.upstream = S3PRLUpstream(upstream)\n",
    "        upstream_dim = self.upstream.hidden_sizes[0]\n",
    "\n",
    "        layer_dims = [upstream_dim] + [hidden_dim] * hidden_layers\n",
    "\n",
    "        self.downstream = torch.nn.Sequential(\n",
    "            *[\n",
    "                torch.nn.Sequential(torch.nn.Linear(dim_in, dim_out), torch.nn.ReLU())\n",
    "                for dim_in, dim_out in zip(layer_dims[:-1], layer_dims[1:])\n",
    "            ]\n",
    "        )\n",
    "        self.out_layer = torch.nn.Linear(\n",
    "            layer_dims[-1], self.num_classes\n",
    "        )  # FIXME: add this at the end of the downstream?\n",
    "\n",
    "        if isinstance(upstream_layers_output_to_use, int):\n",
    "            upstream_layers_output_to_use = [upstream_layers_output_to_use]\n",
    "        elif upstream_layers_output_to_use == 'all':\n",
    "            upstream_layers_output_to_use = list(range(len(self.upstream.hidden_sizes)))\n",
    "\n",
    "        self.upstream_layers_output_to_use = upstream_layers_output_to_use\n",
    "\n",
    "        self.avg_weights = torch.nn.Parameter(\n",
    "            torch.ones(\n",
    "                len(upstream_layers_output_to_use),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.accuracy_top1 = torchmetrics.classification.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes\n",
    "        )\n",
    "        self.accuracy_top5 = torchmetrics.classification.Accuracy(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, top_k=5\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        hidden = self.forward_upstream(x)\n",
    "\n",
    "        w = torch.nn.functional.softmax(self.avg_weights, dim=0)\n",
    "\n",
    "        avg_hidden = torch.sum(\n",
    "            hidden[:, self.upstream_layers_output_to_use] * w[None, :, None],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        return self.out_layer(self.downstream(avg_hidden))\n",
    "\n",
    "    def forward_upstream(self, x) -> torch.Tensor:\n",
    "        if (\n",
    "            not x.get(\"upstream_embedding_precalculated\").all().item()\n",
    "        ):  # Check if all instances have the embedding precalculated\n",
    "            with torch.no_grad():\n",
    "                hidden, _ = self.upstream(x['wav'], wavs_len=x['wav_lens'])\n",
    "            hidden = torch.stack(hidden).transpose(0, 1)\n",
    "        else:\n",
    "            hidden = x['upstream_embedding']\n",
    "        return hidden\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: torch.Tensor,\n",
    "        batch_idx: int,  # pylint: disable=unused-argument\n",
    "    ):\n",
    "        losses = self.calculate_loss(batch)\n",
    "        self.log_results(losses, 'train')\n",
    "        return losses\n",
    "\n",
    "    def validation_step(\n",
    "        self,\n",
    "        batch: torch.Tensor,\n",
    "        batch_idx: int,  # pylint: disable=unused-argument\n",
    "    ):\n",
    "        losses = self.calculate_loss(batch)\n",
    "        self.log_results(losses, 'val')\n",
    "\n",
    "    def test_step(\n",
    "        self,\n",
    "        batch: torch.Tensor,\n",
    "        batch_idx: int,  # pylint: disable=unused-argument\n",
    "    ) -> None:\n",
    "        losses = self.calculate_loss(batch)\n",
    "\n",
    "        out = self(batch)\n",
    "        yhat = out.squeeze()\n",
    "        y = batch['class_id']\n",
    "        accuracy_top1 = self.accuracy_top1(yhat, y)\n",
    "        accuracy_top5 = self.accuracy_top5(yhat, y)\n",
    "\n",
    "        self.log_results(losses, 'test')\n",
    "        self.log_results(accuracy_top1, 'test', 'accuracy_top1')\n",
    "        self.log_results(accuracy_top5, 'test', 'accuracy_top5')\n",
    "\n",
    "    def calculate_loss(self, x: torch.Tensor):\n",
    "        out = self(x)\n",
    "        yhat = out.squeeze()\n",
    "        y = x['class_id']\n",
    "\n",
    "        if len(yhat.shape) == 1:\n",
    "            yhat = yhat.unsqueeze(dim=0)\n",
    "\n",
    "        return torch.nn.functional.cross_entropy(yhat, y)\n",
    "\n",
    "    def log_results(self, losses, prefix, metric=\"loss\") -> None:\n",
    "        log_loss = {\n",
    "            \"time\": int(datetime.now().strftime('%y%m%d%H%M%S')),\n",
    "            metric: losses,\n",
    "        }\n",
    "        self.log_dict({'{}_{}'.format(prefix, k): v for k, v in log_loss.items()})\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ) -> Dict[str, Any]:\n",
    "        optimizer = self.optimizer(params=self.parameters())\n",
    "        optimizer_config = {\"optimizer\": optimizer}\n",
    "        if self.lr_scheduler is not None:\n",
    "            lr_scheduler_config = {\n",
    "                \"scheduler\": self.lr_scheduler(optimizer),\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "            optimizer_config['lr_scheduler'] = lr_scheduler_config\n",
    "        return optimizer_config\n",
    "\n",
    "    def set_optimizer_state(self, state: Dict[str, Any]) -> None:\n",
    "        self.opt_state = state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715933b5-fbbb-4b57-a6ad-341fccd56d90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Make inference from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f6201b-a856-4857-a675-7d1741b34454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d2530f-c103-4929-bc40-91a53c0260fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = joblib.load(\"../speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f0d547-b338-43c1-8a23-9a2fa0f738b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = S3PRLUpstreamMLPDownstreamForCls(\n",
    "    state=state,\n",
    "    hidden_layers=1,\n",
    "    hidden_dim=4096,\n",
    "    optimizer=torch.optim.Adam,\n",
    ")\n",
    "checkpoint = torch.load(\"../speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=52-step=100700.ckpt\")\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55f2bee-9561-4bae-adda-1b8250e8f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_embedding = torch.load(\"/home/eernst/Voxceleb1/avg_embeddings/id10020_1elTcNGC3q8_00022.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6ad5b3-2981-40d4-8a4e-00e24f802e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upstream_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d421aa-7ea3-443f-a48b-925193d192ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model({\"upstream_embedding\": upstream_embedding.unsqueeze(dim=0), \"upstream_embedding_precalculated\": torch.Tensor([True])})\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3f29f-62b8-4a10-93a7-62564b751165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Delete upstream from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d833ec89-1bde-4ae0-82d9-01b5b065a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6efa8d3-5000-4959-bac3-c08009e0922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_clean = deepcopy(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15fac332-58b6-4e06-a596-5eb4e71c9266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'MixedPrecision'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_clean.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6f9105-02a5-4ca8-a812-ebb5023b50f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['avg_weights', 'upstream.upstream.model.mask_emb', 'upstream.upstream.model.feature_extractor.conv_layers.0.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.0.2.weight', 'upstream.upstream.model.feature_extractor.conv_layers.0.2.bias', 'upstream.upstream.model.feature_extractor.conv_layers.1.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.2.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.3.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.4.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.5.0.weight', 'upstream.upstream.model.feature_extractor.conv_layers.6.0.weight', 'upstream.upstream.model.post_extract_proj.weight', 'upstream.upstream.model.post_extract_proj.bias', 'upstream.upstream.model.encoder.pos_conv.0.bias', 'upstream.upstream.model.encoder.pos_conv.0.weight_g', 'upstream.upstream.model.encoder.pos_conv.0.weight_v', 'upstream.upstream.model.encoder.layers.0.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.0.self_attn.relative_attention_bias.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.0.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.0.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.0.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.0.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.0.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.0.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.0.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.0.fc1.weight', 'upstream.upstream.model.encoder.layers.0.fc1.bias', 'upstream.upstream.model.encoder.layers.0.fc2.weight', 'upstream.upstream.model.encoder.layers.0.fc2.bias', 'upstream.upstream.model.encoder.layers.0.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.0.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.1.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.1.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.1.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.1.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.1.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.1.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.1.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.1.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.1.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.1.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.1.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.1.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.1.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.1.fc1.weight', 'upstream.upstream.model.encoder.layers.1.fc1.bias', 'upstream.upstream.model.encoder.layers.1.fc2.weight', 'upstream.upstream.model.encoder.layers.1.fc2.bias', 'upstream.upstream.model.encoder.layers.1.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.1.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.2.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.2.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.2.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.2.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.2.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.2.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.2.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.2.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.2.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.2.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.2.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.2.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.2.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.2.fc1.weight', 'upstream.upstream.model.encoder.layers.2.fc1.bias', 'upstream.upstream.model.encoder.layers.2.fc2.weight', 'upstream.upstream.model.encoder.layers.2.fc2.bias', 'upstream.upstream.model.encoder.layers.2.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.2.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.3.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.3.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.3.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.3.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.3.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.3.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.3.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.3.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.3.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.3.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.3.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.3.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.3.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.3.fc1.weight', 'upstream.upstream.model.encoder.layers.3.fc1.bias', 'upstream.upstream.model.encoder.layers.3.fc2.weight', 'upstream.upstream.model.encoder.layers.3.fc2.bias', 'upstream.upstream.model.encoder.layers.3.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.3.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.4.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.4.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.4.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.4.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.4.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.4.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.4.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.4.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.4.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.4.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.4.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.4.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.4.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.4.fc1.weight', 'upstream.upstream.model.encoder.layers.4.fc1.bias', 'upstream.upstream.model.encoder.layers.4.fc2.weight', 'upstream.upstream.model.encoder.layers.4.fc2.bias', 'upstream.upstream.model.encoder.layers.4.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.4.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.5.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.5.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.5.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.5.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.5.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.5.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.5.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.5.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.5.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.5.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.5.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.5.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.5.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.5.fc1.weight', 'upstream.upstream.model.encoder.layers.5.fc1.bias', 'upstream.upstream.model.encoder.layers.5.fc2.weight', 'upstream.upstream.model.encoder.layers.5.fc2.bias', 'upstream.upstream.model.encoder.layers.5.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.5.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.6.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.6.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.6.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.6.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.6.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.6.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.6.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.6.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.6.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.6.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.6.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.6.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.6.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.6.fc1.weight', 'upstream.upstream.model.encoder.layers.6.fc1.bias', 'upstream.upstream.model.encoder.layers.6.fc2.weight', 'upstream.upstream.model.encoder.layers.6.fc2.bias', 'upstream.upstream.model.encoder.layers.6.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.6.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.7.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.7.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.7.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.7.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.7.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.7.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.7.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.7.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.7.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.7.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.7.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.7.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.7.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.7.fc1.weight', 'upstream.upstream.model.encoder.layers.7.fc1.bias', 'upstream.upstream.model.encoder.layers.7.fc2.weight', 'upstream.upstream.model.encoder.layers.7.fc2.bias', 'upstream.upstream.model.encoder.layers.7.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.7.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.8.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.8.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.8.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.8.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.8.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.8.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.8.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.8.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.8.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.8.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.8.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.8.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.8.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.8.fc1.weight', 'upstream.upstream.model.encoder.layers.8.fc1.bias', 'upstream.upstream.model.encoder.layers.8.fc2.weight', 'upstream.upstream.model.encoder.layers.8.fc2.bias', 'upstream.upstream.model.encoder.layers.8.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.8.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.9.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.9.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.9.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.9.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.9.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.9.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.9.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.9.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.9.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.9.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.9.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.9.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.9.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.9.fc1.weight', 'upstream.upstream.model.encoder.layers.9.fc1.bias', 'upstream.upstream.model.encoder.layers.9.fc2.weight', 'upstream.upstream.model.encoder.layers.9.fc2.bias', 'upstream.upstream.model.encoder.layers.9.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.9.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.10.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.10.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.10.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.10.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.10.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.10.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.10.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.10.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.10.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.10.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.10.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.10.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.10.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.10.fc1.weight', 'upstream.upstream.model.encoder.layers.10.fc1.bias', 'upstream.upstream.model.encoder.layers.10.fc2.weight', 'upstream.upstream.model.encoder.layers.10.fc2.bias', 'upstream.upstream.model.encoder.layers.10.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.10.final_layer_norm.bias', 'upstream.upstream.model.encoder.layers.11.self_attn.grep_a', 'upstream.upstream.model.encoder.layers.11.self_attn.k_proj.weight', 'upstream.upstream.model.encoder.layers.11.self_attn.k_proj.bias', 'upstream.upstream.model.encoder.layers.11.self_attn.v_proj.weight', 'upstream.upstream.model.encoder.layers.11.self_attn.v_proj.bias', 'upstream.upstream.model.encoder.layers.11.self_attn.q_proj.weight', 'upstream.upstream.model.encoder.layers.11.self_attn.q_proj.bias', 'upstream.upstream.model.encoder.layers.11.self_attn.out_proj.weight', 'upstream.upstream.model.encoder.layers.11.self_attn.out_proj.bias', 'upstream.upstream.model.encoder.layers.11.self_attn.grep_linear.weight', 'upstream.upstream.model.encoder.layers.11.self_attn.grep_linear.bias', 'upstream.upstream.model.encoder.layers.11.self_attn_layer_norm.weight', 'upstream.upstream.model.encoder.layers.11.self_attn_layer_norm.bias', 'upstream.upstream.model.encoder.layers.11.fc1.weight', 'upstream.upstream.model.encoder.layers.11.fc1.bias', 'upstream.upstream.model.encoder.layers.11.fc2.weight', 'upstream.upstream.model.encoder.layers.11.fc2.bias', 'upstream.upstream.model.encoder.layers.11.final_layer_norm.weight', 'upstream.upstream.model.encoder.layers.11.final_layer_norm.bias', 'upstream.upstream.model.encoder.layer_norm.weight', 'upstream.upstream.model.encoder.layer_norm.bias', 'upstream.upstream.model.layer_norm.weight', 'upstream.upstream.model.layer_norm.bias', 'downstream.0.0.weight', 'downstream.0.0.bias', 'out_layer.weight', 'out_layer.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_clean['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d8b0813-8f09-4b1f-be46-d9de8c992c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_keys = list(checkpoint_clean['state_dict'].keys())\n",
    "for key in model_state_keys:\n",
    "    if key.startswith(\"upstream\"):\n",
    "        del checkpoint_clean['state_dict'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d692a25-62ba-4903-9678-c7c8ae42aded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['avg_weights', 'downstream.0.0.weight', 'downstream.0.0.bias', 'out_layer.weight', 'out_layer.bias'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_clean['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "914148a9-26a9-419d-97c5-ed1bddb44899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 52,\n",
       " 'global_step': 100700,\n",
       " 'pytorch-lightning_version': '2.2.0.post0',\n",
       " 'state_dict': OrderedDict([('avg_weights',\n",
       "               tensor([0.9748, 0.9834, 0.9907, 0.9892, 0.9957, 1.0095, 1.0282, 1.0282, 1.0211,\n",
       "                       1.0268, 1.0337, 1.0138, 0.9327], device='cuda:0')),\n",
       "              ('downstream.0.0.weight',\n",
       "               tensor([[-0.0295,  0.0338, -0.0306,  ...,  0.0119,  0.0276,  0.0250],\n",
       "                       [ 0.0399,  0.0216,  0.0165,  ..., -0.0096,  0.0119,  0.0121],\n",
       "                       [ 0.0121,  0.0246,  0.0221,  ...,  0.0051,  0.0272,  0.0275],\n",
       "                       ...,\n",
       "                       [ 0.0045,  0.0237, -0.0173,  ..., -0.0288, -0.0116,  0.0337],\n",
       "                       [ 0.0079, -0.0195, -0.0240,  ..., -0.0047,  0.0133,  0.0240],\n",
       "                       [ 0.0082,  0.0203, -0.0200,  ..., -0.0167, -0.0037,  0.0164]],\n",
       "                      device='cuda:0')),\n",
       "              ('downstream.0.0.bias',\n",
       "               tensor([-0.0201,  0.0015,  0.0307,  ..., -0.0211, -0.0041,  0.0102],\n",
       "                      device='cuda:0')),\n",
       "              ('out_layer.weight',\n",
       "               tensor([[-0.0128,  0.0057,  0.0036,  ..., -0.0153,  0.0105, -0.0162],\n",
       "                       [-0.0094, -0.0109, -0.0077,  ...,  0.0040, -0.0109, -0.0071],\n",
       "                       [-0.0100,  0.0076, -0.0091,  ...,  0.0004, -0.0009,  0.0079],\n",
       "                       ...,\n",
       "                       [ 0.0108, -0.0115, -0.0076,  ..., -0.0132,  0.0045,  0.0107],\n",
       "                       [-0.0036,  0.0138,  0.0118,  ..., -0.0070, -0.0180, -0.0088],\n",
       "                       [ 0.0089, -0.0384, -0.0108,  ...,  0.0064, -0.0006, -0.0089]],\n",
       "                      device='cuda:0')),\n",
       "              ('out_layer.bias',\n",
       "               tensor([ 1.0350e-02,  1.1288e-02,  1.5025e-02,  8.8461e-03, -8.0846e-03,\n",
       "                       -5.3144e-03,  1.2655e-02,  9.9973e-03,  7.4926e-03, -1.1779e-02,\n",
       "                        9.1267e-03, -5.9013e-03,  9.6289e-03,  1.2292e-02,  7.4087e-03,\n",
       "                        9.0690e-03,  7.5115e-03,  6.0724e-03, -1.3422e-02,  8.9802e-03,\n",
       "                        3.5830e-03,  8.0847e-03,  8.7108e-03, -7.0216e-03, -1.2752e-02,\n",
       "                        7.1144e-03, -1.2395e-02,  1.1406e-02, -5.2062e-03,  8.1538e-03,\n",
       "                       -1.0510e-02, -1.3656e-02,  1.3886e-02, -9.0874e-03,  1.2984e-02,\n",
       "                       -9.2918e-03,  1.0442e-02, -1.5099e-02,  1.3209e-02, -1.4890e-02,\n",
       "                        2.9331e-03, -4.0852e-03, -7.2303e-03,  2.4316e-03, -1.3960e-04,\n",
       "                       -6.5591e-03,  5.8276e-03,  8.6974e-03, -3.4233e-03,  4.7543e-04,\n",
       "                       -5.2946e-03, -2.4050e-03, -5.0432e-03, -8.3820e-03,  9.7296e-03,\n",
       "                       -1.6688e-04,  1.3714e-02, -1.2887e-02,  1.4102e-02,  7.9250e-03,\n",
       "                       -5.8189e-03, -1.0047e-02, -9.3073e-03, -1.5894e-02,  9.5069e-03,\n",
       "                       -5.8581e-03,  1.4991e-03, -6.4342e-03,  1.5027e-02,  1.2221e-02,\n",
       "                       -5.1668e-03,  1.2372e-02, -5.9570e-03, -1.4509e-02, -1.6620e-03,\n",
       "                        1.4857e-02, -2.8383e-03, -3.9454e-03, -7.5412e-03, -1.2302e-02,\n",
       "                       -9.0800e-04,  1.7329e-04, -1.0857e-02,  1.4241e-02, -9.5615e-03,\n",
       "                        2.7060e-03,  1.3048e-02,  1.0357e-02, -3.0462e-05, -1.4246e-02,\n",
       "                        1.0831e-02, -8.1685e-03,  1.2371e-03,  6.8554e-04, -1.4185e-02,\n",
       "                        9.8525e-03, -9.5692e-03, -6.2138e-03, -1.4573e-02, -1.2778e-02],\n",
       "                      device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 100699},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 100700,\n",
       "     'completed': 100700,\n",
       "     'started': 100700,\n",
       "     'processed': 100700},\n",
       "    'current': {'ready': 1900,\n",
       "     'completed': 1900,\n",
       "     'started': 1900,\n",
       "     'processed': 1900},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 100700,\n",
       "       'completed': 100700},\n",
       "      'current': {'ready': 1900, 'completed': 1900}},\n",
       "     'zero_grad': {'total': {'ready': 100700,\n",
       "       'completed': 100700,\n",
       "       'started': 100700},\n",
       "      'current': {'ready': 1900, 'completed': 1900, 'started': 1900}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 38,\n",
       "     'completed': 38,\n",
       "     'started': 38,\n",
       "     'processed': 38},\n",
       "    'current': {'ready': 38, 'completed': 38, 'started': 38, 'processed': 38},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 53,\n",
       "     'completed': 52,\n",
       "     'started': 53,\n",
       "     'processed': 52},\n",
       "    'current': {'ready': 53,\n",
       "     'completed': 52,\n",
       "     'started': 53,\n",
       "     'processed': 52}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'val_loss',\n",
       "   'best_model_score': tensor(4.3904, device='cuda:0'),\n",
       "   'best_model_path': '/home/eernst/speech-hypertuning/speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=52-step=100700.ckpt',\n",
       "   'current_score': tensor(4.3904, device='cuda:0'),\n",
       "   'dirpath': '/home/eernst/speech-hypertuning/speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints',\n",
       "   'best_k_models': {'/home/eernst/speech-hypertuning/speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=52-step=100700.ckpt': tensor(4.3904, device='cuda:0')},\n",
       "   'kth_best_model_path': '/home/eernst/speech-hypertuning/speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=52-step=100700.ckpt',\n",
       "   'kth_value': tensor(4.3904, device='cuda:0'),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(100649.),\n",
       "     'exp_avg': tensor([-0.0006,  0.0007,  0.0002, -0.0009, -0.0005,  0.0002, -0.0007, -0.0003,\n",
       "             -0.0004, -0.0007, -0.0026, -0.0018,  0.0074], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([8.8721e-05, 5.9450e-05, 5.9045e-05, 3.9275e-05, 2.5314e-05, 1.4115e-05,\n",
       "             1.7130e-05, 2.3495e-05, 4.1355e-05, 1.1392e-04, 1.3630e-04, 5.5431e-05,\n",
       "             9.8604e-05], device='cuda:0')},\n",
       "    249: {'step': tensor(100649.),\n",
       "     'exp_avg': tensor([[ 1.3780e-04, -1.6214e-04,  4.0074e-05,  ...,  9.0076e-05,\n",
       "               2.1302e-05, -2.2386e-03],\n",
       "             [-5.3234e-05,  1.7832e-04, -1.1623e-05,  ...,  1.1784e-05,\n",
       "               4.3109e-05,  7.5986e-05],\n",
       "             [ 3.5604e-05, -2.7257e-05,  3.0433e-05,  ...,  2.4761e-05,\n",
       "              -7.8703e-06, -2.2964e-03],\n",
       "             ...,\n",
       "             [ 1.2437e-04, -7.9634e-05,  2.7491e-05,  ...,  5.8354e-05,\n",
       "              -1.7860e-05, -2.6552e-03],\n",
       "             [-9.8453e-05, -7.2283e-05, -3.5389e-05,  ...,  4.6592e-05,\n",
       "               6.3275e-05,  3.3346e-04],\n",
       "             [ 4.1454e-05, -2.4728e-04,  9.9706e-06,  ...,  8.6110e-05,\n",
       "              -4.0888e-05, -2.0036e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.2098e-07, 2.7375e-07, 4.4995e-08,  ..., 6.2967e-08, 3.6008e-08,\n",
       "              3.9060e-05],\n",
       "             [1.1224e-07, 3.1526e-07, 4.0131e-08,  ..., 7.6702e-08, 3.6738e-08,\n",
       "              3.6200e-05],\n",
       "             [9.1541e-08, 2.5678e-07, 3.2247e-08,  ..., 5.6474e-08, 2.5808e-08,\n",
       "              2.9778e-05],\n",
       "             ...,\n",
       "             [8.1118e-08, 1.8908e-07, 3.2821e-08,  ..., 4.8065e-08, 2.5721e-08,\n",
       "              2.8705e-05],\n",
       "             [9.3200e-08, 1.9897e-07, 3.1333e-08,  ..., 4.8405e-08, 2.7451e-08,\n",
       "              3.0043e-05],\n",
       "             [8.1142e-08, 2.5952e-07, 3.1890e-08,  ..., 5.1094e-08, 2.4922e-08,\n",
       "              2.8391e-05]], device='cuda:0')},\n",
       "    250: {'step': tensor(100649.),\n",
       "     'exp_avg': tensor([-0.0031,  0.0007, -0.0032,  ..., -0.0046,  0.0021, -0.0027],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.1903e-04, 1.1043e-04, 9.0768e-05,  ..., 8.4202e-05, 8.8277e-05,\n",
       "             8.2519e-05], device='cuda:0')},\n",
       "    251: {'step': tensor(100649.),\n",
       "     'exp_avg': tensor([[ 3.7037e-04, -1.8231e-04, -2.5079e-04,  ...,  2.8284e-04,\n",
       "               1.2650e-04, -1.2137e-04],\n",
       "             [ 4.2202e-04,  3.1055e-04,  3.5798e-04,  ...,  5.2075e-04,\n",
       "               2.6343e-04,  3.6162e-04],\n",
       "             [ 4.8520e-04,  4.0254e-04,  4.1335e-04,  ...,  5.3446e-04,\n",
       "               3.0875e-04,  3.9442e-04],\n",
       "             ...,\n",
       "             [-1.8837e-03, -1.7478e-04, -4.7767e-04,  ..., -1.3169e-03,\n",
       "              -9.0151e-04,  8.6410e-05],\n",
       "             [ 4.6024e-04,  3.3361e-04,  3.3744e-04,  ...,  4.8012e-04,\n",
       "               2.7763e-04,  3.5498e-04],\n",
       "             [-1.2049e-04,  3.0877e-04,  2.2634e-04,  ...,  4.4532e-05,\n",
       "               7.3442e-05,  2.5235e-04]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.8369e-05, 3.0043e-05, 2.0797e-05,  ..., 9.0805e-06, 7.8021e-06,\n",
       "              1.2014e-05],\n",
       "             [1.3075e-05, 2.0071e-05, 1.8872e-05,  ..., 1.9709e-05, 6.7917e-06,\n",
       "              9.2555e-06],\n",
       "             [1.5351e-05, 2.1846e-05, 1.9584e-05,  ..., 1.8016e-05, 5.1316e-06,\n",
       "              1.1948e-05],\n",
       "             ...,\n",
       "             [4.2793e-05, 1.1312e-05, 1.3096e-05,  ..., 4.1569e-05, 1.0757e-05,\n",
       "              1.0121e-05],\n",
       "             [1.8288e-05, 2.9165e-05, 1.3449e-05,  ..., 3.3383e-05, 5.1017e-06,\n",
       "              4.1380e-06],\n",
       "             [9.6477e-05, 2.0059e-06, 1.1942e-05,  ..., 4.5261e-05, 1.6174e-05,\n",
       "              1.7499e-05]], device='cuda:0')},\n",
       "    252: {'step': tensor(100649.),\n",
       "     'exp_avg': tensor([-0.0035,  0.0091,  0.0106,  0.0083,  0.0106, -0.0219, -0.0329, -0.0705,\n",
       "              0.0099, -0.0081,  0.0103,  0.0100,  0.0110, -0.0030,  0.0102,  0.0101,\n",
       "             -0.1005,  0.0099,  0.0099,  0.0105,  0.0100,  0.0105,  0.0099,  0.0017,\n",
       "              0.0099,  0.0102,  0.0107,  0.0076,  0.0103,  0.0097,  0.0095, -0.0798,\n",
       "              0.0081,  0.0096,  0.0109,  0.0103,  0.0069, -0.0026, -0.0103,  0.0020,\n",
       "              0.0104,  0.0069,  0.0097,  0.0006,  0.0072,  0.0103, -0.0161, -0.0287,\n",
       "              0.0088, -0.0557,  0.0094,  0.0098, -0.0491,  0.0096,  0.0103,  0.0015,\n",
       "              0.0100,  0.0097,  0.0100,  0.0101, -0.0432,  0.0100,  0.0086, -0.0068,\n",
       "              0.0106, -0.0533,  0.0098,  0.0094,  0.0099,  0.0104,  0.0105,  0.0081,\n",
       "              0.0097,  0.0102,  0.0096,  0.0098, -0.0261,  0.0096,  0.0064,  0.0058,\n",
       "              0.0088,  0.0106, -0.0141,  0.0102,  0.0097,  0.0101,  0.0109,  0.0073,\n",
       "              0.0034, -0.0627,  0.0095,  0.0100,  0.0089,  0.0097,  0.0093,  0.0087,\n",
       "              0.0089, -0.0202,  0.0091,  0.0034], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([0.0118, 0.0100, 0.0095, 0.0110, 0.0086, 0.0106, 0.0088, 0.0137, 0.0090,\n",
       "             0.0097, 0.0086, 0.0082, 0.0092, 0.0092, 0.0088, 0.0093, 0.0112, 0.0085,\n",
       "             0.0089, 0.0097, 0.0087, 0.0104, 0.0112, 0.0112, 0.0091, 0.0092, 0.0084,\n",
       "             0.0118, 0.0084, 0.0100, 0.0103, 0.0109, 0.0107, 0.0115, 0.0088, 0.0078,\n",
       "             0.0108, 0.0098, 0.0109, 0.0094, 0.0083, 0.0108, 0.0097, 0.0112, 0.0118,\n",
       "             0.0095, 0.0108, 0.0095, 0.0096, 0.0090, 0.0091, 0.0094, 0.0097, 0.0092,\n",
       "             0.0096, 0.0107, 0.0093, 0.0104, 0.0112, 0.0094, 0.0088, 0.0093, 0.0092,\n",
       "             0.0110, 0.0079, 0.0088, 0.0099, 0.0102, 0.0087, 0.0112, 0.0079, 0.0110,\n",
       "             0.0105, 0.0093, 0.0102, 0.0083, 0.0111, 0.0098, 0.0098, 0.0109, 0.0093,\n",
       "             0.0098, 0.0105, 0.0086, 0.0096, 0.0104, 0.0113, 0.0100, 0.0096, 0.0101,\n",
       "             0.0077, 0.0105, 0.0096, 0.0093, 0.0098, 0.0113, 0.0113, 0.0111, 0.0089,\n",
       "             0.0107], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 1e-06,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23,\n",
       "      24,\n",
       "      25,\n",
       "      26,\n",
       "      27,\n",
       "      28,\n",
       "      29,\n",
       "      30,\n",
       "      31,\n",
       "      32,\n",
       "      33,\n",
       "      34,\n",
       "      35,\n",
       "      36,\n",
       "      37,\n",
       "      38,\n",
       "      39,\n",
       "      40,\n",
       "      41,\n",
       "      42,\n",
       "      43,\n",
       "      44,\n",
       "      45,\n",
       "      46,\n",
       "      47,\n",
       "      48,\n",
       "      49,\n",
       "      50,\n",
       "      51,\n",
       "      52,\n",
       "      53,\n",
       "      54,\n",
       "      55,\n",
       "      56,\n",
       "      57,\n",
       "      58,\n",
       "      59,\n",
       "      60,\n",
       "      61,\n",
       "      62,\n",
       "      63,\n",
       "      64,\n",
       "      65,\n",
       "      66,\n",
       "      67,\n",
       "      68,\n",
       "      69,\n",
       "      70,\n",
       "      71,\n",
       "      72,\n",
       "      73,\n",
       "      74,\n",
       "      75,\n",
       "      76,\n",
       "      77,\n",
       "      78,\n",
       "      79,\n",
       "      80,\n",
       "      81,\n",
       "      82,\n",
       "      83,\n",
       "      84,\n",
       "      85,\n",
       "      86,\n",
       "      87,\n",
       "      88,\n",
       "      89,\n",
       "      90,\n",
       "      91,\n",
       "      92,\n",
       "      93,\n",
       "      94,\n",
       "      95,\n",
       "      96,\n",
       "      97,\n",
       "      98,\n",
       "      99,\n",
       "      100,\n",
       "      101,\n",
       "      102,\n",
       "      103,\n",
       "      104,\n",
       "      105,\n",
       "      106,\n",
       "      107,\n",
       "      108,\n",
       "      109,\n",
       "      110,\n",
       "      111,\n",
       "      112,\n",
       "      113,\n",
       "      114,\n",
       "      115,\n",
       "      116,\n",
       "      117,\n",
       "      118,\n",
       "      119,\n",
       "      120,\n",
       "      121,\n",
       "      122,\n",
       "      123,\n",
       "      124,\n",
       "      125,\n",
       "      126,\n",
       "      127,\n",
       "      128,\n",
       "      129,\n",
       "      130,\n",
       "      131,\n",
       "      132,\n",
       "      133,\n",
       "      134,\n",
       "      135,\n",
       "      136,\n",
       "      137,\n",
       "      138,\n",
       "      139,\n",
       "      140,\n",
       "      141,\n",
       "      142,\n",
       "      143,\n",
       "      144,\n",
       "      145,\n",
       "      146,\n",
       "      147,\n",
       "      148,\n",
       "      149,\n",
       "      150,\n",
       "      151,\n",
       "      152,\n",
       "      153,\n",
       "      154,\n",
       "      155,\n",
       "      156,\n",
       "      157,\n",
       "      158,\n",
       "      159,\n",
       "      160,\n",
       "      161,\n",
       "      162,\n",
       "      163,\n",
       "      164,\n",
       "      165,\n",
       "      166,\n",
       "      167,\n",
       "      168,\n",
       "      169,\n",
       "      170,\n",
       "      171,\n",
       "      172,\n",
       "      173,\n",
       "      174,\n",
       "      175,\n",
       "      176,\n",
       "      177,\n",
       "      178,\n",
       "      179,\n",
       "      180,\n",
       "      181,\n",
       "      182,\n",
       "      183,\n",
       "      184,\n",
       "      185,\n",
       "      186,\n",
       "      187,\n",
       "      188,\n",
       "      189,\n",
       "      190,\n",
       "      191,\n",
       "      192,\n",
       "      193,\n",
       "      194,\n",
       "      195,\n",
       "      196,\n",
       "      197,\n",
       "      198,\n",
       "      199,\n",
       "      200,\n",
       "      201,\n",
       "      202,\n",
       "      203,\n",
       "      204,\n",
       "      205,\n",
       "      206,\n",
       "      207,\n",
       "      208,\n",
       "      209,\n",
       "      210,\n",
       "      211,\n",
       "      212,\n",
       "      213,\n",
       "      214,\n",
       "      215,\n",
       "      216,\n",
       "      217,\n",
       "      218,\n",
       "      219,\n",
       "      220,\n",
       "      221,\n",
       "      222,\n",
       "      223,\n",
       "      224,\n",
       "      225,\n",
       "      226,\n",
       "      227,\n",
       "      228,\n",
       "      229,\n",
       "      230,\n",
       "      231,\n",
       "      232,\n",
       "      233,\n",
       "      234,\n",
       "      235,\n",
       "      236,\n",
       "      237,\n",
       "      238,\n",
       "      239,\n",
       "      240,\n",
       "      241,\n",
       "      242,\n",
       "      243,\n",
       "      244,\n",
       "      245,\n",
       "      246,\n",
       "      247,\n",
       "      248,\n",
       "      249,\n",
       "      250,\n",
       "      251,\n",
       "      252]}]}],\n",
       " 'lr_schedulers': [],\n",
       " 'MixedPrecision': {'scale': 32768.0,\n",
       "  'growth_factor': 2.0,\n",
       "  'backoff_factor': 0.5,\n",
       "  'growth_interval': 2000,\n",
       "  '_growth_tracker': 649}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9904509d-9fe5-4bea-9002-936d68e415cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint_clean, \"model_clean.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669059da-dac6-4d1a-8bbc-e500e2ec0f0f",
   "metadata": {},
   "source": [
    "### Test inference with cached upstream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6df3333-e3bc-4550-b2b6-f2ab606eb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = S3PRLUpstreamMLPDownstreamForCls(\n",
    "    state=state,\n",
    "    hidden_layers=1,\n",
    "    hidden_dim=4096,\n",
    "    optimizer=torch.optim.Adam,\n",
    ")\n",
    "new_checkpoint = torch.load(\"../speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=52-step=100700.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e607ef35-6e2d-43d8-8f90-c3848d7f2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in checkpoint['state_dict'].items():\n",
    "    if key.startswith(\"upstream\"):\n",
    "        new_checkpoint['state_dict'][key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a10e76d-1cae-45f5-b00b-dd64947770ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4092fac4-51fc-43a7-a2ea-241ee58c80e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = new_model({\"upstream_embedding\": upstream_embedding.unsqueeze(dim=0), \"upstream_embedding_precalculated\": torch.Tensor([True])})\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62403307-d36d-4360-930e-fbb27760d286",
   "metadata": {},
   "source": [
    "# Clean memory from project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe68628-abaf-4407-be64-662723c605fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45044c1b-edf1-4054-9304-c18d71ae7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"../speech_hypertuning/experiments/batch_size_vs_learning_rate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62446be7-78ff-4550-8a3f-b55864ac39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/home/eernst/.cache/pypoetry/virtualenvs/speech-hypertuning-ED-71ySj-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = S3PRLUpstreamMLPDownstreamForCls(\n",
    "    state=state,\n",
    "    hidden_layers=1,\n",
    "    hidden_dim=4096,\n",
    "    optimizer=torch.optim.Adam,\n",
    ") #TODO: take from state\n",
    "original_checkpoint = torch.load(\"../speech_hypertuning/experiments/batch_size_vs_learning_rate/batch_size_1-lr_0.000001/checkpoints/epoch=999-step=1900000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bed73a-e774-4d12-8329-25b86defa0c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning batch_size_1-lr_0.0005\n",
      "batch_size_1-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_128-lr_0.000001\n",
      "Succesfully cleaned batch_size_128-lr_0.000001\n",
      "Cleaning batch_size_8-lr_0.1\n",
      "batch_size_8-lr_0.1 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.000005\n",
      "batch_size_1900-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_16-lr_0.05\n",
      "batch_size_16-lr_0.05 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.00005\n",
      "batch_size_1900-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_4-lr_0.001\n",
      "batch_size_4-lr_0.001 already cleaned\n",
      "Cleaning batch_size_256-lr_0.000005\n",
      "batch_size_256-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.05\n",
      "batch_size_1024-lr_0.05 already cleaned\n",
      "Cleaning batch_size_2-lr_0.5\n",
      "batch_size_2-lr_0.5 already cleaned\n",
      "Cleaning batch_size_128-lr_0.0001\n",
      "batch_size_128-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_512-lr_0.5\n",
      "batch_size_512-lr_0.5 already cleaned\n",
      "Cleaning batch_size_512-lr_1\n",
      "batch_size_512-lr_1 already cleaned\n",
      "Cleaning batch_size_64-lr_0.5\n",
      "batch_size_64-lr_0.5 already cleaned\n",
      "Cleaning batch_size_16-lr_0.005\n",
      "batch_size_16-lr_0.005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.000005\n",
      "batch_size_32-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.000005\n",
      "batch_size_1024-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_4-lr_0.5\n",
      "batch_size_4-lr_0.5 already cleaned\n",
      "Cleaning batch_size_16-lr_0.000005\n",
      "batch_size_16-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_256-lr_0.05\n",
      "batch_size_256-lr_0.05 already cleaned\n",
      "Cleaning batch_size_1-lr_0.00005\n",
      "batch_size_1-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.1\n",
      "batch_size_32-lr_0.1 already cleaned\n",
      "Cleaning batch_size_2-lr_0.05\n",
      "batch_size_2-lr_0.05 already cleaned\n",
      "Cleaning batch_size_1-lr_0.00001\n",
      "batch_size_1-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_256-lr_0.000001\n",
      "Succesfully cleaned batch_size_256-lr_0.000001\n",
      "Cleaning batch_size_8-lr_1\n",
      "batch_size_8-lr_1 already cleaned\n",
      "Cleaning batch_size_1-lr_0.5\n",
      "batch_size_1-lr_0.5 already cleaned\n",
      "Cleaning batch_size_32-lr_0.0001\n",
      "batch_size_32-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.5\n",
      "batch_size_1024-lr_0.5 already cleaned\n",
      "Cleaning batch_size_4-lr_0.1\n",
      "batch_size_4-lr_0.1 already cleaned\n",
      "Cleaning batch_size_256-lr_0.005\n",
      "batch_size_256-lr_0.005 already cleaned\n",
      "Cleaning batch_size_128-lr_0.00001\n",
      "batch_size_128-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_4-lr_0.0001\n",
      "batch_size_4-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.01\n",
      "batch_size_128-lr_0.01 already cleaned\n",
      "Cleaning batch_size_8-lr_0.01\n",
      "batch_size_8-lr_0.01 already cleaned\n",
      "Cleaning batch_size_1-lr_0.005\n",
      "batch_size_1-lr_0.005 already cleaned\n",
      "Cleaning batch_size_512-lr_0.05\n",
      "batch_size_512-lr_0.05 already cleaned\n",
      "Cleaning batch_size_256-lr_1\n",
      "batch_size_256-lr_1 already cleaned\n",
      "Cleaning batch_size_2-lr_0.001\n",
      "batch_size_2-lr_0.001 already cleaned\n",
      "Cleaning batch_size_32-lr_0.00001\n",
      "batch_size_32-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.005\n",
      "batch_size_1900-lr_0.005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.5\n",
      "batch_size_32-lr_0.5 already cleaned\n",
      "Cleaning batch_size_512-lr_0.000001\n",
      "Succesfully cleaned batch_size_512-lr_0.000001\n",
      "Cleaning batch_size_1900-lr_1\n",
      "batch_size_1900-lr_1 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.00001\n",
      "batch_size_1024-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_8-lr_0.005\n",
      "batch_size_8-lr_0.005 already cleaned\n",
      "Cleaning batch_size_1-lr_1\n",
      "batch_size_1-lr_1 already cleaned\n",
      "Cleaning batch_size_1-lr_0.000001\n",
      "Succesfully cleaned batch_size_1-lr_0.000001\n",
      "Cleaning batch_size_2-lr_0.000005\n",
      "batch_size_2-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_64-lr_0.001\n",
      "batch_size_64-lr_0.001 already cleaned\n",
      "Cleaning batch_size_512-lr_0.000005\n",
      "batch_size_512-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_4-lr_1\n",
      "batch_size_4-lr_1 already cleaned\n",
      "Cleaning batch_size_2-lr_0.1\n",
      "batch_size_2-lr_0.1 already cleaned\n",
      "Cleaning batch_size_1-lr_0.0001\n",
      "batch_size_1-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.05\n",
      "batch_size_128-lr_0.05 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.1\n",
      "batch_size_1024-lr_0.1 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.005\n",
      "batch_size_1024-lr_0.005 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.001\n",
      "batch_size_1024-lr_0.001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.5\n",
      "batch_size_128-lr_0.5 already cleaned\n",
      "Cleaning batch_size_64-lr_0.05\n",
      "batch_size_64-lr_0.05 already cleaned\n",
      "Cleaning batch_size_2-lr_0.00001\n",
      "batch_size_2-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_16-lr_0.01\n",
      "batch_size_16-lr_0.01 already cleaned\n",
      "Cleaning batch_size_8-lr_0.000001\n",
      "Succesfully cleaned batch_size_8-lr_0.000001\n",
      "Cleaning batch_size_512-lr_0.001\n",
      "batch_size_512-lr_0.001 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.0005\n",
      "batch_size_1024-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.00001\n",
      "batch_size_8-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_1-lr_0.001\n",
      "batch_size_1-lr_0.001 already cleaned\n",
      "Cleaning batch_size_1-lr_0.1\n",
      "batch_size_1-lr_0.1 already cleaned\n",
      "Cleaning batch_size_64-lr_0.01\n",
      "batch_size_64-lr_0.01 already cleaned\n",
      "Cleaning batch_size_8-lr_0.000005\n",
      "batch_size_8-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_64-lr_0.1\n",
      "batch_size_64-lr_0.1 already cleaned\n",
      "Cleaning batch_size_256-lr_0.5\n",
      "batch_size_256-lr_0.5 already cleaned\n",
      "Cleaning batch_size_16-lr_0.0005\n",
      "batch_size_16-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_16-lr_0.5\n",
      "batch_size_16-lr_0.5 already cleaned\n",
      "Cleaning batch_size_4-lr_0.00005\n",
      "batch_size_4-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_2-lr_0.005\n",
      "batch_size_2-lr_0.005 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.0001\n",
      "batch_size_1024-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_2-lr_0.0001\n",
      "batch_size_2-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_4-lr_0.01\n",
      "batch_size_4-lr_0.01 already cleaned\n",
      "Cleaning batch_size_8-lr_0.001\n",
      "batch_size_8-lr_0.001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.005\n",
      "batch_size_128-lr_0.005 already cleaned\n",
      "Cleaning batch_size_64-lr_0.000001\n",
      "Succesfully cleaned batch_size_64-lr_0.000001\n",
      "Cleaning batch_size_2-lr_0.01\n",
      "batch_size_2-lr_0.01 already cleaned\n",
      "Cleaning batch_size_4-lr_0.000001\n",
      "Succesfully cleaned batch_size_4-lr_0.000001\n",
      "Cleaning batch_size_1024-lr_0.000001\n",
      "Succesfully cleaned batch_size_1024-lr_0.000001\n",
      "Cleaning batch_size_512-lr_0.0001\n",
      "batch_size_512-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.00005\n",
      "batch_size_128-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.0001\n",
      "batch_size_8-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_32-lr_0.000001\n",
      "Succesfully cleaned batch_size_32-lr_0.000001\n",
      "Cleaning batch_size_1900-lr_0.1\n",
      "batch_size_1900-lr_0.1 already cleaned\n",
      "Cleaning batch_size_64-lr_0.0001\n",
      "batch_size_64-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_64-lr_0.00005\n",
      "batch_size_64-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_128-lr_0.000005\n",
      "batch_size_128-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_4-lr_0.05\n",
      "batch_size_4-lr_0.05 already cleaned\n",
      "Cleaning batch_size_32-lr_0.01\n",
      "batch_size_32-lr_0.01 already cleaned\n",
      "Cleaning batch_size_16-lr_1\n",
      "batch_size_16-lr_1 already cleaned\n",
      "Cleaning batch_size_256-lr_0.00005\n",
      "batch_size_256-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_256-lr_0.0001\n",
      "batch_size_256-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_256-lr_0.01\n",
      "batch_size_256-lr_0.01 already cleaned\n",
      "Cleaning batch_size_1-lr_0.000005\n",
      "batch_size_1-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_4-lr_0.00001\n",
      "batch_size_4-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_512-lr_0.01\n",
      "batch_size_512-lr_0.01 already cleaned\n",
      "Cleaning batch_size_512-lr_0.005\n",
      "batch_size_512-lr_0.005 already cleaned\n",
      "Cleaning batch_size_16-lr_0.000001\n",
      "Succesfully cleaned batch_size_16-lr_0.000001\n",
      "Cleaning batch_size_256-lr_0.0005\n",
      "batch_size_256-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_64-lr_0.00001\n",
      "batch_size_64-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_64-lr_0.0005\n",
      "batch_size_64-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_1-lr_0.01\n",
      "batch_size_1-lr_0.01 already cleaned\n",
      "Cleaning batch_size_1024-lr_0.00005\n",
      "batch_size_1024-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_2-lr_0.000001\n",
      "Succesfully cleaned batch_size_2-lr_0.000001\n",
      "Cleaning batch_size_2-lr_0.0005\n",
      "batch_size_2-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.5\n",
      "batch_size_8-lr_0.5 already cleaned\n",
      "Cleaning batch_size_512-lr_0.00005\n",
      "batch_size_512-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.00005\n",
      "batch_size_32-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.0005\n",
      "batch_size_1900-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.00005\n",
      "batch_size_8-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_1-lr_0.05\n",
      "batch_size_1-lr_0.05 already cleaned\n",
      "Cleaning batch_size_2-lr_1\n",
      "batch_size_2-lr_1 already cleaned\n",
      "Cleaning batch_size_64-lr_1\n",
      "batch_size_64-lr_1 already cleaned\n",
      "Cleaning batch_size_512-lr_0.1\n",
      "batch_size_512-lr_0.1 already cleaned\n",
      "Cleaning batch_size_32-lr_1\n",
      "batch_size_32-lr_1 already cleaned\n",
      "Cleaning batch_size_4-lr_0.005\n",
      "batch_size_4-lr_0.005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.0005\n",
      "batch_size_32-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_2-lr_0.00005\n",
      "batch_size_2-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.000001\n",
      "Succesfully cleaned batch_size_1900-lr_0.000001\n",
      "Cleaning batch_size_1024-lr_0.01\n",
      "Cleaning batch_size_4-lr_0.000005\n",
      "batch_size_4-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.05\n",
      "batch_size_8-lr_0.05 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.001\n",
      "batch_size_1900-lr_0.001 already cleaned\n",
      "Cleaning batch_size_256-lr_0.001\n",
      "batch_size_256-lr_0.001 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.0001\n",
      "batch_size_1900-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_16-lr_0.1\n",
      "batch_size_16-lr_0.1 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.5\n",
      "batch_size_1900-lr_0.5 already cleaned\n",
      "Cleaning batch_size_4-lr_0.0005\n",
      "batch_size_4-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.00001\n",
      "batch_size_1900-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_16-lr_0.0001\n",
      "batch_size_16-lr_0.0001 already cleaned\n",
      "Cleaning batch_size_128-lr_1\n",
      "batch_size_128-lr_1 already cleaned\n",
      "Cleaning batch_size_64-lr_0.000005\n",
      "batch_size_64-lr_0.000005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.001\n",
      "batch_size_32-lr_0.001 already cleaned\n",
      "Cleaning batch_size_256-lr_0.1\n",
      "batch_size_256-lr_0.1 already cleaned\n",
      "Cleaning batch_size_64-lr_0.005\n",
      "batch_size_64-lr_0.005 already cleaned\n",
      "Cleaning batch_size_128-lr_0.0005\n",
      "batch_size_128-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_16-lr_0.00005\n",
      "batch_size_16-lr_0.00005 already cleaned\n",
      "Cleaning batch_size_8-lr_0.0005\n",
      "batch_size_8-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_1024-lr_1\n",
      "batch_size_1024-lr_1 already cleaned\n",
      "Cleaning batch_size_16-lr_0.001\n",
      "batch_size_16-lr_0.001 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.01\n",
      "batch_size_1900-lr_0.01 already cleaned\n",
      "Cleaning batch_size_32-lr_0.05\n",
      "batch_size_32-lr_0.05 already cleaned\n",
      "Cleaning batch_size_128-lr_0.1\n",
      "batch_size_128-lr_0.1 already cleaned\n",
      "Cleaning batch_size_16-lr_0.00001\n",
      "batch_size_16-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_512-lr_0.00001\n",
      "batch_size_512-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_128-lr_0.001\n",
      "batch_size_128-lr_0.001 already cleaned\n",
      "Cleaning batch_size_512-lr_0.0005\n",
      "batch_size_512-lr_0.0005 already cleaned\n",
      "Cleaning batch_size_32-lr_0.005\n",
      "batch_size_32-lr_0.005 already cleaned\n",
      "Cleaning batch_size_256-lr_0.00001\n",
      "batch_size_256-lr_0.00001 already cleaned\n",
      "Cleaning batch_size_1900-lr_0.05\n",
      "batch_size_1900-lr_0.05 already cleaned\n"
     ]
    }
   ],
   "source": [
    "states_paths = Path(project_path).rglob('*state.pkl')\n",
    "for path in states_paths:\n",
    "    experiment_name = path.parent.name\n",
    "    print(f\"Cleaning {experiment_name}\") \n",
    "    state = joblib.load(path)\n",
    "    checkpoint_paths = list(path.parent.rglob('*checkpoints/*.ckpt'))\n",
    "    if len(checkpoint_paths) == 1:\n",
    "        if not 'test_metrics' in state:\n",
    "            print(\"Not test metrics in state, skipping\")\n",
    "            continue\n",
    "        checkpoint_path = str(checkpoint_paths[0])\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "        # Delete\n",
    "        model_state_keys = list(checkpoint['state_dict'].keys())\n",
    "        if not any(key.startswith(\"upstream\") for key in model_state_keys):\n",
    "            print(f\"{experiment_name} already cleaned\")\n",
    "            continue\n",
    "        for key in model_state_keys:\n",
    "            if key.startswith(\"upstream\"):\n",
    "                del checkpoint['state_dict'][key]\n",
    "                \n",
    "        # Replace checkpoint\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "        # Test saved\n",
    "        new_checkpoint = torch.load(checkpoint_path)\n",
    "        for key, value in original_checkpoint['state_dict'].items():\n",
    "            if key.startswith(\"upstream\"):\n",
    "                new_checkpoint['state_dict'][key] = value\n",
    "                \n",
    "        msg = model.load_state_dict(new_checkpoint['state_dict'])\n",
    "        if str(msg) == \"<All keys matched successfully>\":\n",
    "            print(f\"Succesfully cleaned {experiment_name}\")\n",
    "        else:\n",
    "            raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5144f-935b-47ed-8ce5-7b8bcb9eaae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
