execute_pipeline:
    tasks = [@tasks.utils.set_seed,
             @tasks.load_data.load_dataset]
    execution_order = 'sequential'

tasks.utils.set_seed.seed=%SEED

train/torch.utils.data.DataLoader:
    shuffle=True
    batch_size=%TRAIN_BATCH_SIZE
    num_workers=%TRAIN_DATALOADER_NUM_WORKERS
    collate_fn=@tasks.load_data.dynamic_pad_batch

val/torch.utils.data.DataLoader:
    shuffle=False
    batch_size=%VAL_BATCH_SIZE
    num_workers=%VAL_DATALOADER_NUM_WORKERS
    collate_fn=@tasks.load_data.dynamic_pad_batch

pl.loggers.CSVLogger:
    save_dir=%OUTPUT_DIR
    name='pretrain_logs'